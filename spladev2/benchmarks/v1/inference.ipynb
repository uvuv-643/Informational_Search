{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a6154be-b280-4a63-b5db-a4aed52615b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:45:36.538785Z",
     "iopub.status.busy": "2025-11-06T11:45:36.537818Z",
     "iopub.status.idle": "2025-11-06T11:58:56.563733Z",
     "shell.execute_reply": "2025-11-06T11:58:56.562512Z",
     "shell.execute_reply.started": "2025-11-06T11:45:36.538745Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import gc\n",
    "\n",
    "with open('./merged_sorted.pkl', 'rb') as f:\n",
    "    documents = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf2f09d-9298-4274-bb29-3da330bd9ab0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T12:26:50.508979Z",
     "iopub.status.busy": "2025-11-06T12:26:50.508003Z",
     "iopub.status.idle": "2025-11-06T12:26:56.864048Z",
     "shell.execute_reply": "2025-11-06T12:26:56.863201Z",
     "shell.execute_reply.started": "2025-11-06T12:26:50.508946Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ir_datasets in /home/jupyter/.local/lib/python3.10/site-packages (0.5.11)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.11.2)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (2.6.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.9.3)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (1.26.4)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (4.66.5)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (2.6)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (4.4.5)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (0.2.5)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (0.1.10)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (3.4.0.post0)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (0.2.3)\n",
      "Requirement already satisfied: pyarrow>=16.1.0 in /home/jupyter/.local/lib/python3.10/site-packages (from ir_datasets) (17.0.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2023.7.22)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /home/jupyter/.local/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir_datasets) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install ir_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d53740-c13e-4843-a6b2-82048bf1af4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T12:26:56.866182Z",
     "iopub.status.busy": "2025-11-06T12:26:56.865670Z",
     "iopub.status.idle": "2025-11-06T12:26:57.544221Z",
     "shell.execute_reply": "2025-11-06T12:26:57.543568Z",
     "shell.execute_reply.started": "2025-11-06T12:26:56.866156Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries: 101093\n"
     ]
    }
   ],
   "source": [
    "import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load(\"msmarco-passage/dev\")\n",
    "\n",
    "queries_count = sum(1 for _ in dataset.queries_iter())\n",
    "print(f\"Number of queries: {queries_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eae2dcb-6394-4cf3-979e-3f4c1c6af35a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T12:26:57.545545Z",
     "iopub.status.busy": "2025-11-06T12:26:57.545047Z",
     "iopub.status.idle": "2025-11-06T12:26:57.562378Z",
     "shell.execute_reply": "2025-11-06T12:26:57.561832Z",
     "shell.execute_reply.started": "2025-11-06T12:26:57.545522Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–∞—Ä query-passage ===\n",
      "Query 1102432 -> Passage 2026790, Relevance: 1\n",
      "Query 1102431 -> Passage 7066866, Relevance: 1\n",
      "Query 1102431 -> Passage 7066867, Relevance: 1\n",
      "Query 1090282 -> Passage 7066900, Relevance: 1\n",
      "Query 39449 -> Passage 7066905, Relevance: 1\n",
      "Query 76162 -> Passage 7066915, Relevance: 1\n",
      "Query 195512 -> Passage 7066971, Relevance: 1\n",
      "Query 1090280 -> Passage 7067004, Relevance: 1\n",
      "Query 331318 -> Passage 5309290, Relevance: 1\n",
      "Query 300674 -> Passage 7067032, Relevance: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"=== –ü—Ä–∏–º–µ—Ä—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø–∞—Ä query-passage ===\")\n",
    "for i, qrel in enumerate(dataset.qrels_iter()):\n",
    "    if i >= 10:  # –ü–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 10\n",
    "        break\n",
    "    print(f\"Query {qrel.query_id} -> Passage {qrel.doc_id}, Relevance: {qrel.relevance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7871e3fd-ae5a-4de4-81ea-8a6b6c7a5566",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T12:26:57.564024Z",
     "iopub.status.busy": "2025-11-06T12:26:57.563490Z",
     "iopub.status.idle": "2025-11-06T12:29:10.226889Z",
     "shell.execute_reply": "2025-11-06T12:29:10.226152Z",
     "shell.execute_reply.started": "2025-11-06T12:26:57.564001Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from splade.splade.models.transformer_rep import Splade\n",
    "\n",
    "model_type_or_dir = \"naver/splade-cocondenser-ensembledistil\"\n",
    "\n",
    "model = Splade(model_type_or_dir, agg=\"max\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type_or_dir)\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c32f312c-6d8f-4818-9479-9e943f38f906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T12:30:36.465719Z",
     "iopub.status.busy": "2025-11-06T12:30:36.465040Z",
     "iopub.status.idle": "2025-11-06T12:30:36.477266Z",
     "shell.execute_reply": "2025-11-06T12:30:36.476716Z",
     "shell.execute_reply.started": "2025-11-06T12:30:36.465692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ce216ed-b565-4269-99bb-89d5ff352561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T16:23:27.709805Z",
     "iopub.status.busy": "2025-11-06T16:23:27.708620Z",
     "iopub.status.idle": "2025-11-06T16:23:27.870635Z",
     "shell.execute_reply": "2025-11-06T16:23:27.870030Z",
     "shell.execute_reply.started": "2025-11-06T16:23:27.709765Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [00:00, 375201.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "qrels_mapping = {}\n",
    "for qrel in dataset.qrels_iter():\n",
    "    qrels_mapping.setdefault(qrel.query_id, {})[qrel.doc_id] = qrel.relevance\n",
    "    \n",
    "import numpy as np\n",
    "import heapq\n",
    "\n",
    "def search_top10(query_bow_rep, optimized_posting_lists, top_k=10):\n",
    "    all_doc_ids = []\n",
    "    all_weights = []\n",
    "    \n",
    "    for term, weight in query_bow_rep:\n",
    "        if term in optimized_posting_lists:\n",
    "            doc_ids, scores = optimized_posting_lists[term]\n",
    "            all_doc_ids.append(doc_ids)\n",
    "            all_weights.append(scores * weight)\n",
    "    \n",
    "    if not all_doc_ids:\n",
    "        return []\n",
    "    \n",
    "    all_doc_ids = np.concatenate(all_doc_ids)\n",
    "    all_weights = np.concatenate(all_weights)\n",
    "    \n",
    "    unique_docs, inverse_indices = np.unique(all_doc_ids, return_inverse=True)\n",
    "    doc_scores = np.zeros_like(unique_docs, dtype=np.float32)\n",
    "    \n",
    "    np.add.at(doc_scores, inverse_indices, all_weights)\n",
    "    \n",
    "    if len(doc_scores) <= top_k:\n",
    "        top_indices = np.argsort(doc_scores)[::-1]\n",
    "    else:\n",
    "        top_indices = np.argpartition(doc_scores, -top_k)[-top_k:]\n",
    "        top_indices = top_indices[np.argsort(doc_scores[top_indices])[::-1]]\n",
    "    \n",
    "    return [(doc_scores[i], unique_docs[i]) for i in top_indices]\n",
    "\n",
    "mrr = 0\n",
    "count = 0\n",
    "responses = []\n",
    "nullable = 0\n",
    "for query in tqdm(dataset.queries_iter()):\n",
    "    count += 1\n",
    "    if count > 5000:\n",
    "        break\n",
    "    query_id = query.query_id\n",
    "    relevant_passages = qrels_mapping.get(query_id, {})\n",
    "    \n",
    "    if len(relevant_passages) == 0:\n",
    "        nullable += 1\n",
    "    else:\n",
    "        continue\n",
    "    if len(relevant_passages) > 0:\n",
    "        inputs = tokenizer(query.text, return_tensors=\"pt\")\n",
    "        inputs = {k: v for k, v in inputs.items()}\n",
    "\n",
    "        query_rep = model(d_kwargs=inputs)[\"d_rep\"].squeeze()\n",
    "\n",
    "        nonzero_mask = query_rep != 0\n",
    "        col = torch.nonzero(nonzero_mask).squeeze()\n",
    "        weights = query_rep[col]\n",
    "\n",
    "        sorted_weights, sorted_indices = torch.sort(weights, descending=True)\n",
    "        sorted_col = col[sorted_indices]\n",
    "\n",
    "        sorted_col_cpu = sorted_col.cpu().tolist()\n",
    "        sorted_weights_cpu = sorted_weights.cpu().tolist()\n",
    "            \n",
    "        bow_rep = []\n",
    "        for k, v in zip(sorted_col_cpu, sorted_weights_cpu):\n",
    "            bow_rep.append((reverse_voc[k], v))\n",
    "        \n",
    "        # print('started')\n",
    "        # –ü–æ–∏—Å–∫ —Ç–æ–ø-10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\n",
    "        top10_docs = search_top10(bow_rep, optimized_posting_lists, top_k=10)\n",
    "        # print(f\"Query: {query.text}\", )\n",
    "        # print(f\"Top-10 documents: {top10_docs}\")\n",
    "        found = False\n",
    "        for index, doc in enumerate(top10_docs):\n",
    "            doc_id = doc[1]\n",
    "            if str(doc_id) in list(relevant_passages.keys()):\n",
    "                responses.append(f\"Query: {query.text} {index + 1}\")\n",
    "                mrr += 1 / (index + 1)\n",
    "                found = True\n",
    "                break\n",
    "                \n",
    "        if not found:\n",
    "            responses.append(f\"Query: {query.text} 0\")\n",
    "        \n",
    "                \n",
    "print(mrr / 5000)\n",
    "        # print('finished')\n",
    "        \n",
    "print(mrr / 2781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fb9ad-fc04-4809-89f7-e8c90fe6424e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('result.txt', 'w') as f:\n",
    "    f.write(str({\"a\": mrr / 5000, \"b\": str(responses)}))\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6545b23d-d9e0-43f7-93e2-dd7c48e4bf2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T17:10:17.761339Z",
     "iopub.status.busy": "2025-11-03T17:10:17.760917Z",
     "iopub.status.idle": "2025-11-03T17:10:17.776359Z",
     "shell.execute_reply": "2025-11-03T17:10:17.775567Z",
     "shell.execute_reply.started": "2025-11-03T17:10:17.761318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenericQuery(query_id='1048578', text='cost of endless pools/swim spa')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947e71ec-8b55-45f3-950d-d7aad9c099cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T17:45:38.408168Z",
     "iopub.status.busy": "2025-11-03T17:45:38.407796Z",
     "iopub.status.idle": "2025-11-03T17:49:54.741237Z",
     "shell.execute_reply": "2025-11-03T17:49:54.740284Z",
     "shell.execute_reply.started": "2025-11-03T17:45:38.408143Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sorting arrays: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27714/27714 [04:16<00:00, 108.25it/s] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "def sort_dict_cuda_inplace(data_dict):\n",
    "    keys_list = list(data_dict.keys())\n",
    "    \n",
    "    for key in tqdm(keys_list, desc=\"Sorting arrays\"):\n",
    "        arr = data_dict[key]\n",
    "        \n",
    "        if len(arr) == 0:\n",
    "            continue\n",
    "            \n",
    "        values = np.array([x[1] for x in arr], dtype=np.float32)\n",
    "        \n",
    "        gpu_values = cp.asarray(values)\n",
    "        gpu_indices = cp.argsort(-gpu_values)\n",
    "        sorted_indices = cp.asnumpy(gpu_indices)\n",
    "        \n",
    "        sorted_arr = [arr[i] for i in sorted_indices]\n",
    "        \n",
    "        data_dict[key] = sorted_arr\n",
    "        \n",
    "        del gpu_values, gpu_indices, values, sorted_indices, arr\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    \n",
    "    return data_dict\n",
    "\n",
    "\n",
    "sorted_data = sort_dict_cuda_inplace(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34009649-8077-4294-9eb8-7698f7263d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T17:49:54.758360Z",
     "iopub.status.busy": "2025-11-03T17:49:54.758038Z",
     "iopub.status.idle": "2025-11-03T18:05:22.842837Z",
     "shell.execute_reply": "2025-11-03T18:05:22.841887Z",
     "shell.execute_reply.started": "2025-11-03T17:49:54.758340Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('./merged_sorted.pkl', 'wb') as f:\n",
    "    pickle.dump(sorted_data, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "130d9771-b78d-4937-955d-3b44806a9de5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T18:07:46.402479Z",
     "iopub.status.busy": "2025-11-03T18:07:46.402048Z",
     "iopub.status.idle": "2025-11-03T18:07:46.438029Z",
     "shell.execute_reply": "2025-11-03T18:07:46.437306Z",
     "shell.execute_reply.started": "2025-11-03T18:07:46.402457Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('136689', 0.010684899985790253)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(sorted_data['cat'], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f55ce-5f02-4a5b-85c6-5abae17097f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c903ac6a-1ded-4f77-835a-4bde4b0d75cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T09:54:53.737793Z",
     "iopub.status.busy": "2025-11-04T09:54:53.736972Z",
     "iopub.status.idle": "2025-11-04T09:54:53.751741Z",
     "shell.execute_reply": "2025-11-04T09:54:53.750951Z",
     "shell.execute_reply.started": "2025-11-04T09:54:53.737765Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27715"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24720429-44b9-4fdd-8cc0-86b0d11134ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-04T09:55:22.244126Z",
     "iopub.status.busy": "2025-11-04T09:55:22.242978Z",
     "iopub.status.idle": "2025-11-04T09:55:22.270163Z",
     "shell.execute_reply": "2025-11-04T09:55:22.269179Z",
     "shell.execute_reply.started": "2025-11-04T09:55:22.244097Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many dimensions 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3469/3276370889.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_ids_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'"
     ]
    }
   ],
   "source": [
    "torch.tensor(doc_ids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71e460af-d367-40d4-a64e-005635ff9f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T10:51:54.709443Z",
     "iopub.status.busy": "2025-11-06T10:51:54.708743Z",
     "iopub.status.idle": "2025-11-06T10:51:54.721095Z",
     "shell.execute_reply": "2025-11-06T10:51:54.720457Z",
     "shell.execute_reply.started": "2025-11-06T10:51:54.709417Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('8549863', 1.310231328010559)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents['cat'][50451]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ca2ea5-0837-4a95-842d-544a306928d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T11:25:57.696620Z",
     "iopub.status.busy": "2025-11-06T11:25:57.695966Z",
     "iopub.status.idle": "2025-11-06T11:45:03.498655Z",
     "shell.execute_reply": "2025-11-06T11:45:03.497109Z",
     "shell.execute_reply.started": "2025-11-06T11:25:57.696584Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–†–∞–∑–º–µ—Ä –¥–æ: 0.001221 –ì–ë\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñé         | 998/27714 [04:48<1:04:38,  6.89it/s] IOStream.flush timed out\n",
      " 18%|‚ñà‚ñä        | 5025/27714 [19:05<1:26:12,  4.39it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4513/3283103920.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposting_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moptimized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mposting_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimized_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4513/3283103920.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptimized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposting_list\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moptimized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mposting_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0moptimized_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsizeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimized\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "original_size = sys.getsizeof(documents) / (1024**3)\n",
    "print(f\"–†–∞–∑–º–µ—Ä –¥–æ: {original_size:.6f} –ì–ë\")\n",
    "\n",
    "optimized = {}\n",
    "for term, posting_list in tqdm(documents.items()):\n",
    "    optimized[term] = [(int(doc_id), np.float16(score)) for doc_id, score in posting_list]\n",
    "\n",
    "optimized_size = sys.getsizeof(optimized) / (1024**3)\n",
    "print(f\"–†–∞–∑–º–µ—Ä –ø–æ—Å–ª–µ: {optimized_size:.6f} –ì–ë\")\n",
    "print(f\"–≠–∫–æ–Ω–æ–º–∏—è: {(1 - optimized_size/original_size)*100:.2f}%\")\n",
    "\n",
    "with open('optimized.pkl', 'wb') as f:\n",
    "    pickle.dump(optimized, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15315f9-4beb-475c-9e6b-1d7f2f6e03c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T12:12:29.299455Z",
     "iopub.status.busy": "2025-11-06T12:12:29.298746Z",
     "iopub.status.idle": "2025-11-06T12:24:10.627941Z",
     "shell.execute_reply": "2025-11-06T12:24:10.627058Z",
     "shell.execute_reply.started": "2025-11-06T12:12:29.299426Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 27714/27714 [11:41<00:00, 39.52it/s]  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def optimize_posting_lists(posting_lists):\n",
    "    optimized = {}\n",
    "    for term, docs_scores in tqdm(posting_lists.items()):\n",
    "        doc_ids = np.array([x[0] for x in docs_scores], dtype=np.int32)\n",
    "        scores = np.array([x[1] for x in docs_scores], dtype=np.float32)\n",
    "        optimized[term] = (doc_ids, scores)\n",
    "    return optimized\n",
    "\n",
    "new_documents = optimize_posting_lists(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89be992e-18f4-44dc-b71d-f3b6bd9d5a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T12:24:33.716899Z",
     "iopub.status.busy": "2025-11-06T12:24:33.715992Z",
     "iopub.status.idle": "2025-11-06T12:24:33.738111Z",
     "shell.execute_reply": "2025-11-06T12:24:33.737553Z",
     "shell.execute_reply.started": "2025-11-06T12:24:33.716862Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7733759, 4811806, 2758271, ..., 8480784, 8588158, 8822218],\n",
       "       dtype=int32),\n",
       " array([3.1162891, 3.0853443, 3.0774562, ..., 0.0106849, 0.0106849,\n",
       "        0.0106849], dtype=float32))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_documents['cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7dc6a834-36f1-49b1-a35c-cff34ea0f617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T16:24:00.456130Z",
     "iopub.status.busy": "2025-11-06T16:24:00.455110Z",
     "iopub.status.idle": "2025-11-06T16:24:00.477456Z",
     "shell.execute_reply": "2025-11-06T16:24:00.476759Z",
     "shell.execute_reply.started": "2025-11-06T16:24:00.456092Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39208889117195533"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import json\n",
    "\n",
    "with open(\"result.txt\", \"r\") as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "# 4. Parse using ast.literal_eval() (safer than eval)\n",
    "parsed_data = ast.literal_eval(file_content)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Extract numeric values from your objects\n",
    "# Replace 'value' with the actual property name in your objects\n",
    "old_values = list(map(lambda x: int(x.split(' ')[-1]), eval(parsed_data['b'])))\n",
    "\n",
    "mrr = 0\n",
    "average_mrr = 0\n",
    "values = []\n",
    "for i in range(len(old_values)):\n",
    "    if old_values[i] != 0:\n",
    "        mrr += 1 / old_values[i]\n",
    "    average_mrr = mrr / (i + 1)\n",
    "    values.append(average_mrr)\n",
    "\n",
    "values[2780]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1878d72-0e39-4719-9f46-930b1dd74fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
