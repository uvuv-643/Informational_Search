{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288e0860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (5.1.2)\n",
      "Requirement already satisfied: datasets in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (4.3.0)\n",
      "Requirement already satisfied: torch in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.57.1)\n",
      "Requirement already satisfied: tqdm in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from sentence-transformers) (1.16.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from sentence-transformers) (0.35.3)\n",
      "Requirement already satisfied: Pillow in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from sentence-transformers) (12.0.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.10.23)\n",
      "Requirement already satisfied: requests in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.10)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: setuptools in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/uvuv/Informational_Search/.venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence-transformers datasets torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading queries: 808731it [00:01, 556048.21it/s]\n",
      "Loading docs: 8841823it [00:25, 346259.14it/s]\n",
      "Loading pairs: 39780811it [03:14, 204265.52it/s]\n",
      "Epoch 1:   0%|          | 0/1243151 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q_ids': tensor([[ 101, 2073, 2515,  ...,    0,    0,    0],\n",
      "        [ 101, 6412, 1997,  ...,    0,    0,    0],\n",
      "        [ 101, 2129, 2146,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2779, 3199,  ...,    0,    0,    0],\n",
      "        [ 101, 4633, 1999,  ...,    0,    0,    0],\n",
      "        [ 101, 2054, 2828,  ...,    0,    0,    0]]), 'q_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'p_ids': tensor([[  101,  2073,  2515,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  2942,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  3452,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2045,  2024,  ...,     0,     0,     0],\n",
      "        [  101, 24800,  1021,  ...,     0,     0,     0],\n",
      "        [  101,  3763, 10925,  ...,  1012,   102,     0]]), 'p_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 0]]), 'n_ids': tensor([[ 101, 2000, 2079,  ...,    0,    0,    0],\n",
      "        [ 101, 2172, 1997,  ...,    0,    0,    0],\n",
      "        [ 101, 4983, 2017,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 2058, 1015,  ...,    0,    0,    0],\n",
      "        [ 101, 6041, 1024,  ...,    0,    0,    0],\n",
      "        [ 101, 3097, 3343,  ...,    0,    0,    0]]), 'n_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 1/1243151 [00:09<3433:33:18,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q_ids': tensor([[  101,  2054,  3361,  ...,     0,     0,     0],\n",
      "        [  101, 26568, 27303,  ...,     0,     0,     0],\n",
      "        [  101,  2054,  2003,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2054,  1005,  ...,     0,     0,     0],\n",
      "        [  101,  2129,  2146,  ...,     0,     0,     0],\n",
      "        [  101,  2129,  2172,  ...,     0,     0,     0]]), 'q_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'p_ids': tensor([[  101,  7079,  2115,  ...,     0,     0,     0],\n",
      "        [  101,  8856,  4098,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  3177,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2769,  2915,  ...,     0,     0,     0],\n",
      "        [  101, 20228,  2015,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  8417,  ...,  1996,  5025,   102]]), 'p_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'n_ids': tensor([[  101,  1037, 10882,  ...,     0,     0,     0],\n",
      "        [  101,  2088,  1521,  ...,     0,     0,     0],\n",
      "        [  101,  2054, 16463,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101, 16434,  4162,  ...,     0,     0,     0],\n",
      "        [  101,  1999, 11040,  ...,     0,     0,     0],\n",
      "        [  101,  1996,  4145,  ...,     0,     0,     0]]), 'n_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 1/1243151 [00:16<5702:18:17, 16.51s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 99\u001b[39m\n\u001b[32m     96\u001b[39m n_reps = model(batch[\u001b[33m'\u001b[39m\u001b[33mn_ids\u001b[39m\u001b[33m'\u001b[39m].to(device), batch[\u001b[33m'\u001b[39m\u001b[33mn_mask\u001b[39m\u001b[33m'\u001b[39m].to(device))\n\u001b[32m     98\u001b[39m loss = compute_loss(q_reps, p_reps, n_reps)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m optimizer.step()\n\u001b[32m    102\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Informational_Search/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Informational_Search/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Informational_Search/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import ir_datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MSMARCODataset(Dataset):\n",
    "    def __init__(self, tokenizer, max_length=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        dataset = ir_datasets.load(\"msmarco-passage/train/triples-small\")\n",
    "        \n",
    "        queries = {q.query_id: q.text for q in tqdm(dataset.queries_iter(), desc=\"Loading queries\")}\n",
    "        docs = {d.doc_id: d.text for d in tqdm(dataset.docs_iter(), desc=\"Loading docs\")}\n",
    "        \n",
    "        self.data = []\n",
    "        for i, item in enumerate(tqdm(dataset.docpairs_iter(), desc=\"Loading pairs\")):\n",
    "            self.data.append({\n",
    "                'query': queries[item.query_id],\n",
    "                'pos_doc': docs[item.doc_id_a],\n",
    "                'neg_doc': docs[item.doc_id_b]\n",
    "            })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        query = self.tokenizer(item['query'], truncation=True, padding='max_length', \n",
    "                               max_length=self.max_length, return_tensors='pt')\n",
    "        pos_doc = self.tokenizer(item['pos_doc'], truncation=True, padding='max_length',\n",
    "                                 max_length=self.max_length, return_tensors='pt')\n",
    "        neg_doc = self.tokenizer(item['neg_doc'], truncation=True, padding='max_length',\n",
    "                                 max_length=self.max_length, return_tensors='pt')\n",
    "        return {\n",
    "            'q_ids': query['input_ids'].squeeze(),\n",
    "            'q_mask': query['attention_mask'].squeeze(),\n",
    "            'p_ids': pos_doc['input_ids'].squeeze(),\n",
    "            'p_mask': pos_doc['attention_mask'].squeeze(),\n",
    "            'n_ids': neg_doc['input_ids'].squeeze(),\n",
    "            'n_mask': neg_doc['attention_mask'].squeeze()\n",
    "        }\n",
    "\n",
    "class SPLADE(nn.Module):\n",
    "    def __init__(self, model_name='distilbert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.linear = nn.Linear(768, 30522)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        with torch.no_grad():\n",
    "            output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = self.linear(output.last_hidden_state)\n",
    "        weights = torch.log(1 + torch.relu(logits))\n",
    "        weights = torch.sum(weights * attention_mask.unsqueeze(-1), dim=1)\n",
    "        return weights\n",
    "\n",
    "def compute_loss(q_reps, p_reps, n_reps, lambda_reg=0.0001):\n",
    "    batch_size = q_reps.size(0)\n",
    "    \n",
    "    pos_scores = torch.sum(q_reps * p_reps, dim=1)\n",
    "    neg_scores = torch.sum(q_reps * n_reps, dim=1)\n",
    "    \n",
    "    all_docs = torch.cat([p_reps, n_reps], dim=0)\n",
    "    all_scores = torch.matmul(q_reps, all_docs.T)\n",
    "    \n",
    "    labels = torch.arange(batch_size, device=q_reps.device)\n",
    "    ce_loss = F.cross_entropy(all_scores, labels)\n",
    "    \n",
    "    l1_q = lambda_reg * torch.mean(torch.sum(torch.abs(q_reps), dim=1))\n",
    "    l1_d = lambda_reg * torch.mean(torch.sum(torch.abs(all_docs), dim=1))\n",
    "    \n",
    "    return ce_loss + l1_q + l1_d\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = SPLADE().to(device)\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5)\n",
    "\n",
    "dataset = MSMARCODataset(tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(3):\n",
    "    total_loss = 0\n",
    "    running_loss = 0\n",
    "    for i, batch in enumerate(tqdm(dataloader, desc=f'Epoch {epoch+1}')):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        q_reps = model(batch['q_ids'].to(device), batch['q_mask'].to(device))\n",
    "        p_reps = model(batch['p_ids'].to(device), batch['p_mask'].to(device))\n",
    "        n_reps = model(batch['n_ids'].to(device), batch['n_mask'].to(device))\n",
    "        \n",
    "        loss = compute_loss(q_reps, p_reps, n_reps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            tqdm.write(f'Step {i+1}: avg loss = {running_loss/1000:.4f}')\n",
    "            running_loss = 0\n",
    "    \n",
    "    tqdm.write(f'Epoch {epoch+1} avg loss: {total_loss/len(dataloader):.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'splade_v1.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47796088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is sound times speed\n",
      "the speed of light is much faster than the speed of sound. sound moves at 343 metres per second ( thats about 770 miles per hour! ). the speed of light is a little trickier. in a vacuum it is roughly 300 000 000 metres per second ( so nearly 900 000 times faster than sound! ). however, when light moves through air or glass it gets slowed down a little bit so light moving through glass moves at 200 000 000 metres per second which is still 580 000 times faster than sound.\n",
      "what determines the pitch of sound? pitch is determined by the frequency of a wave, and frequency is the combination of wavelength and speed at which the wave is traveling. sound has a constant speed of 343 meters per second, so wavelength dictates pitch. the longer a sound ' s wavelength, the lower the pitch of that sound.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(batch['q_ids'][2], skip_special_tokens=True))\n",
    "print(tokenizer.decode(batch['p_ids'][2], skip_special_tokens=True))\n",
    "print(tokenizer.decode(batch['n_ids'][2], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2029184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')\n",
    "\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4861e373",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mx\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mNameError\u001b[39m: name 'x' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18c951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
