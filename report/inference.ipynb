{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./merged.pkl', 'rb') as f:\n",
    "    documents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc1231",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ir_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f466f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load(\"msmarco-passage/dev\")\n",
    "\n",
    "queries_count = sum(1 for _ in dataset.queries_iter())\n",
    "print(f\"Number of queries: {queries_count}\")\n",
    "\n",
    "print(\"=== Примеры релевантных пар query-passage ===\")\n",
    "for i, qrel in enumerate(dataset.qrels_iter()):\n",
    "    if i >= 10:  # Покажем первые 10\n",
    "        break\n",
    "    print(f\"Query {qrel.query_id} -> Passage {qrel.doc_id}, Relevance: {qrel.relevance}\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "qrels_mapping = {}\n",
    "for qrel in dataset.qrels_iter():\n",
    "    qrels_mapping.setdefault(qrel.query_id, {})[qrel.doc_id] = qrel.relevance\n",
    "    \n",
    "    \n",
    "for query in tqdm(dataset.queries_iter()):\n",
    "    print(query)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38717768",
   "metadata": {},
   "source": [
    "### Загружаю Splade библиотечный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7476b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "from ..spladev2.cloned.splade.splade.models.transformer_rep import Splade\n",
    "\n",
    "model_type_or_dir = \"naver/splade-cocondenser-ensembledistil\"\n",
    "\n",
    "model = Splade(model_type_or_dir, agg=\"max\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type_or_dir)\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de1fac",
   "metadata": {},
   "source": [
    "### Или Splade самописный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "model_type_or_dir = \"naver/splade-cocondenser-ensembledistil\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class SPLADE(nn.Module):\n",
    "    def __init__(self, model_name='distilbert-base-uncased'):\n",
    "        super().__init__()\n",
    "        self.bert_mlm = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert_mlm(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        relu_logits = F.relu(logits)\n",
    "        relu_logits = relu_logits * attention_mask.unsqueeze(-1)\n",
    "        pooled, _ = torch.max(relu_logits, dim=1)\n",
    "        weights = torch.log1p(pooled)\n",
    "        return weights\n",
    "    \n",
    "model = SPLADE().to(device)\n",
    "model.load_state_dict(torch.load('model.pt'))\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_type_or_dir)\n",
    "reverse_voc = {v: k for k, v in tokenizer.vocab.items()}\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd6bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import heapq\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "count = 0\n",
    "mrr = 0.0\n",
    "\n",
    "import csv\n",
    "\n",
    "def get_document_text(doc_id, file_path=\"collection.tsv\"):\n",
    "    doc_id = str(doc_id)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as fd:\n",
    "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            if row[0] == doc_id:\n",
    "                return row[1]\n",
    "    return None\n",
    "\n",
    "\n",
    "for query in dataset.queries_iter():\n",
    "    if count >= 100:\n",
    "        break\n",
    "    \n",
    "    query_id = query.query_id\n",
    "    relevant_passages = qrels_mapping.get(query_id, {})\n",
    "    \n",
    "    if len(relevant_passages) == 0:\n",
    "        continue\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    inputs = tokenizer(query.text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_rep = model(inputs['input_ids'], inputs['attention_mask'])\n",
    "        \n",
    "\n",
    "    q_rep = q_rep.squeeze()\n",
    "    indices = torch.nonzero(q_rep).flatten()\n",
    "    weights = q_rep[indices]\n",
    "    \n",
    "    q_indices = indices.tolist()\n",
    "    q_weights = weights.tolist()\n",
    "    \n",
    "    q_rep = q_rep.squeeze()\n",
    "    indices = torch.nonzero(q_rep).flatten()\n",
    "    weights = q_rep[indices]\n",
    "    \n",
    "    q_indices = indices.tolist()\n",
    "    q_weights = weights.tolist()\n",
    "    \n",
    "    scores = {}\n",
    "    for idx, q_w in zip(q_indices, q_weights):\n",
    "        token = reverse_voc[idx]\n",
    "        if token in documents:\n",
    "            for doc_id, d_w in documents[token]:\n",
    "                if doc_id in scores:\n",
    "                    scores[doc_id] += q_w * d_w\n",
    "                else:\n",
    "                    scores[doc_id] = q_w * d_w\n",
    "    \n",
    "    top_docs = heapq.nlargest(10, scores.items(), key=lambda x: x[1])\n",
    "    \n",
    "    rank = 0\n",
    "    for i, (doc_id, score) in enumerate(top_docs):\n",
    "        if doc_id in relevant_passages:\n",
    "            rank = i + 1\n",
    "            break\n",
    "\n",
    "    if rank > 0:\n",
    "        mrr += 1 / rank\n",
    "\n",
    "    print(query, get_document_text(top_docs[0][0]))\n",
    "    print(count, rank)\n",
    "\n",
    "print(mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cfadbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import heapq\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "count = 0\n",
    "mrr = 0.0\n",
    "x = 0\n",
    "for query in dataset.queries_iter():\n",
    "    x += 1\n",
    "    if x < 150: \n",
    "        continue\n",
    "        \n",
    "    if count >= 100:\n",
    "        break\n",
    "    \n",
    "    query_id = query.query_id\n",
    "    relevant_passages = qrels_mapping.get(query_id, {})\n",
    "    \n",
    "    if len(relevant_passages) == 0:\n",
    "        continue\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    inputs = tokenizer(query.text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_rep = model(inputs['input_ids'], inputs['attention_mask'])\n",
    "        \n",
    "\n",
    "    q_rep = q_rep.squeeze()\n",
    "    indices = torch.nonzero(q_rep).flatten()\n",
    "    weights = q_rep[indices]\n",
    "    \n",
    "    q_indices = indices.tolist()\n",
    "    q_weights = weights.tolist()\n",
    "    \n",
    "    q_rep = q_rep.squeeze()\n",
    "    indices = torch.nonzero(q_rep).flatten()\n",
    "    weights = q_rep[indices]\n",
    "    \n",
    "    q_indices = indices.tolist()\n",
    "    q_weights = weights.tolist()\n",
    "    \n",
    "    scores = {}\n",
    "    for idx, q_w in zip(q_indices, q_weights):\n",
    "        token = reverse_voc[idx]\n",
    "        if token in documents:\n",
    "            for doc_id, d_w in documents[token]:\n",
    "                if doc_id in scores:\n",
    "                    scores[doc_id] += q_w * d_w\n",
    "                else:\n",
    "                    scores[doc_id] = q_w * d_w\n",
    "    \n",
    "    top_docs = heapq.nlargest(10, scores.items(), key=lambda x: x[1])\n",
    "    \n",
    "    rank = 0\n",
    "    for i, (doc_id, score) in enumerate(top_docs):\n",
    "        if doc_id in relevant_passages:\n",
    "            rank = i + 1\n",
    "            break\n",
    "\n",
    "    if rank > 0:\n",
    "        mrr += 1 / rank\n",
    "\n",
    "    print(query, get_document_text(top_docs[0][0]))\n",
    "    print(count, rank)\n",
    "\n",
    "print(mrr, count, mrr / count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4cb48",
   "metadata": {},
   "source": [
    "### Метрики MRR@10 для различных моделей\n",
    "\n",
    "- **naver/splade-cocondenser-ensembledistil: 0.392**\n",
    "\n",
    "- **tuned mlm bert head: 0.078**\n",
    "\n",
    "    *   Q: cause of pimples on tip of nose  \n",
    "        A: Causes of pimples on nose. A pimple, zit or bump on nose can have different causes. Some of the possible causes would include the following: 1. Stress. Being emotionally stress has the ability to trigger hormonal changes that can interfere with normal function of the body. Common such change is increased secretion of sebum by the sebaceous glands.  \n",
    "        RANK: 1\n",
    "\n",
    "    *   Q: what is web accessibility  \n",
    "        A: If you want to learn the skills required to ensure your organization's web site is accessible, this training will provide what you need. We'll also provide the resources and information you need to empower your organization to meet all of your future accessibility needs.  \n",
    "        RANK: 5\n",
    "\n",
    "    *   Q: who produced transformers  \n",
    "        A: Assuming the question related to the toy line; Transformers first came out in 1984 after Hasbro bought out the Diaclone, Diakron, and micro toy lines. Hasbro created a cartoâ€¦on as an ad campaign and named the toys something better than DK-1.  \n",
    "        RANK: 0\n",
    "\n",
    "- **pretrained mlm bert head, not trained: ~0**\n",
    "\n",
    "    *   Q: what is opportunities in acfta  \n",
    "        A: At the end of a cell cycle, including mitosis, the new cells will have. 23 pairs of chromosomes; 46 total. only the 23 maternal chromosomes. only the 23 paternal chromosomes. 92 chromosomes, as a result of doubling during the S-phase of the cell cycle. Interphase is broken into phases known as. G1, S and G2.  \n",
    "        RANK: 0\n",
    "\n",
    "    *   Q: trend what does it means  \n",
    "        A: Editor s note: This post is a Care2 favorite, back by popular demand. It was originally posted on December 26, 2012. Enjoy! People wear perfume and cologne to feel like they smell clean and fresh or sexy or elegant.  \n",
    "        RANK: 0  \n",
    "\n",
    "    *   Q: trending topic meaning  \n",
    "        A: The term âjaundice, means âyellow in color and refers to the yellowing of a babyâs skin, owing to the accumulation of orange-coloured bilirubin. Yellow Jaundice is common in healthy new-born babies; about 60% of all babies get physiological jaundice ( normal neonatal jaundice ). Physiological jaundice in newborns will usually peak at day 5 and 6 and then fade within a week.  \n",
    "        RANK: 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a7557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
